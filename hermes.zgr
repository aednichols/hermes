grammar {
  lexer<python> {
    r'\grammar' -> grammar_start(:grammar)
    r'\s+' -> null

    mode<grammar> {
      r'\s+' -> null
      r'{' -> grammar_lbrace(:lbrace)
      r'}' -> grammar_rbrace(:rbrace)
      r'lexer\s*<\s*[a-zA-Z]+\s*>' -> lexer_start(:lexer)
      r'parser\s*<\s*ll1\s*>' -> parser_ll1_start(:parser_ll1)
    }

    mode<lexer> {
      r'\s+' -> null
      r'{' -> lexer_lbrace(:lbrace)
      r'}' -> lexer_rbrace(:rbrace)
      r'null' -> :null
      r'\(' -> :lparen
      r'\)' -> :rparen
      r'r\'(\\\'|[^\'])*\'' -> :regex
      r'"(\\\"|[^\"])*"' -> :regex
      r'->' -> :arrow
      r':([a-zA-Z][a-zA-Z0-9_]*|_empty)' -> morpheme(:terminal)
      r'mode<[a-zA-Z0-9_]+>' -> parse_mode(:mode)
      r'partials' -> parse_partials(:partials)
      r'[a-zA-Z][a-zA-Z0-9_]*' -> :identifier
      r'<code>(.*?)</code>' {DOTALL} -> lexer_code(:code)
    }

    mode<partials> {
      r'\s+' -> null
      r'r\'(\\\'|[^\'])*\'' -> :regex
      r'"(\\\"|[^\"])*"' -> :regex
      r'->' -> :arrow
      r'_([a-zA-Z][a-zA-Z0-9_]*)' -> :regex_partial
      r'{' -> :lbrace
      r'}' -> partials_rbrace(:rbrace)
    }

    mode<parser_ll1> {
      r'\s+' -> null
      r'{' -> parser_lbrace(:lbrace)
      r'}' -> parser_rbrace(:rbrace)
      r'\|' -> :pipe
      r'=' -> :equals
      r'\(' -> :lparen
      r'\)' -> :rparen
      r',' -> :comma
      r'->' -> :arrow
      r'parser\s*<\s*expression\s*>' -> parser_expr_start(:parser_expression)
      r':([a-zA-Z][a-zA-Z0-9_]*|_empty)' -> morpheme(:terminal)
      r'\$[a-zA-Z][a-zA-Z0-9_]*(?=\s*\=)' -> parser_rule_start(:nonterminal)
      r'\$[a-zA-Z][a-zA-Z0-9_]*' -> morpheme(:nonterminal)
      r'\$([0-9]+|\$)' -> morpheme(:nonterminal_reference)
      r'[a-zA-Z][a-zA-Z0-9_]*' -> :identifier
      r'"[^"]+"' -> :string
      r'[0-9]+' -> :integer
    }

    mode<parser_expr> {
      r'\s+' -> null
      r'\([\*-]:(left|right|unary)\)' -> binding_power()
      r'->' -> :arrow
      r'<=>' -> :expression_divider
      r'\|' -> :pipe
      r'=' -> :equals
      r'{' -> parser_lbrace(:lbrace)
      r'}' -> parser_rbrace(:rbrace)
      r'\(' -> :lparen
      r'\)' -> :rparen
      r',' -> :comma
      r':([a-zA-Z][a-zA-Z0-9_]*|_empty)' -> morpheme(:terminal)
      r'(\$[a-zA-Z][a-zA-Z0-9_]*)[ \t]*=[ \t]*\1[ \t]+:[a-zA-Z][a-zA-Z0-9_]*[ \t]+\1(?![ \t]+(:|\$))' -> infix_rule_start(:nonterminal)
      r'(\$[a-zA-Z][a-zA-Z0-9_]*)[ \t]*=[ \t]*:[a-zA-Z][a-zA-Z0-9_]*[ \t]+\1(?![ \t](:|\$))' -> prefix_rule_start(:nonterminal)
      r'\$[a-zA-Z][a-zA-Z0-9_]*\s*=' -> expr_rule_start(:nonterminal)
      r'\$[a-zA-Z][a-zA-Z0-9_]*' -> morpheme(:nonterminal)
      r'\$([0-9]+|\$)' -> morpheme(:nonterminal_reference)
      r'[a-zA-Z][a-zA-Z0-9_]*' -> :identifier
      r'"[^"]+"' -> :string
      r'[0-9]+' -> :integer
    }

    <code>
def init():
    return {'lexer_brace': 0, 'grammar_brace': 0, 'parser_brace': 0}
def normalize_morpheme(morpheme):
    if morpheme == '$$': return '$'
    return morpheme.lstrip(':').lstrip('$')
def binding_power(context, mode, match, groups, terminal, resource, line, col):
    (precedence, associativity) = match[1:-1].split(':')
    marker = 'asterisk' if precedence == '*' else 'dash'
    tokens = [
        Terminal(terminals['lparen'], 'lparen', '(', resource, line, col),
        Terminal(terminals[marker], marker, precedence, resource, line, col),
        Terminal(terminals['colon'], 'colon', ':', resource, line, col),
        Terminal(terminals[associativity], associativity, associativity, resource, line, col),
        Terminal(terminals['rparen'], 'rparen', ')', resource, line, col)
    ]
    return (tokens, mode, context)
def morpheme(context, mode, match, groups, terminal, resource, line, col):
    return default_action(context, mode, normalize_morpheme(match), groups, terminal, resource, line, col)
def grammar_start(context, mode, match, groups, terminal, resource, line, col):
    return default_action(context, 'grammar', match, groups, terminal, resource, line, col)
def lexer_start(context, mode, match, groups, terminal, resource, line, col):
    identifier = match.replace('lexer', '').replace('<', '').replace('>', '').strip()
    tokens = [
        Terminal(terminals['lexer'], 'lexer', 'lexer', resource, line, col),
        Terminal(terminals['langle'], 'langle', '<', resource, line, col),
        Terminal(terminals['identifier'], 'identifier', identifier, resource, line, col),
        Terminal(terminals['rangle'], 'rangle', '>', resource, line, col),
    ]
    return (tokens, 'lexer', context)
def parser_ll1_start(context, mode, match, groups, terminal, resource, line, col):
    return default_action(context, 'parser_ll1', match, groups, terminal, resource, line, col)
def parser_expr_start(context, mode, match, groups, terminal, resource, line, col):
    return default_action(context, 'parser_expr', match, groups, terminal, resource, line, col)
def parse_mode(context, mode, match, groups, terminal, resource, line, col):
    identifier = match.replace('mode', '').replace('<', '').replace('>', '').strip()
    tokens = [
        Terminal(terminals['mode'], 'mode', 'mode', resource, line, col),
        Terminal(terminals['langle'], 'langle', '<', resource, line, col),
        Terminal(terminals['identifier'], 'identifier', identifier, resource, line, col),
        Terminal(terminals['rangle'], 'rangle', '>', resource, line, col),
    ]
    return (tokens, mode, context)
def parse_partials(context, mode, match, groups, terminal, resource, line, col):
    return default_action(context, 'partials', match, groups, terminal, resource, line, col)
def partials_rbrace(context, mode, match, groups, terminal, resource, line, col):
    return default_action(context, 'lexer', match, groups, terminal, resource, line, col)
def lexer_code(context, mode, match, groups, terminal, resource, line, col):
    code = match[6:-7].strip()
    tokens = [Terminal(terminals[terminal], terminal, code, resource, line, col)]
    return (tokens, mode, context)
def lexer_lbrace(context, mode, match, groups, terminal, resource, line, col):
    context['lexer_brace'] += 1
    return default_action(context, mode, match, groups, terminal, resource, line, col)
def lexer_rbrace(context, mode, match, groups, terminal, resource, line, col):
    context['lexer_brace'] -= 1
    mode = 'grammar' if context['lexer_brace'] == 0 else mode
    return default_action(context, mode, match, groups, terminal, resource, line, col)
def parser_lbrace(context, mode, match, groups, terminal, resource, line, col):
    context['parser_brace'] += 1
    return default_action(context, mode, match, groups, terminal, resource, line, col)
def parser_rbrace(context, mode, match, groups, terminal, resource, line, col):
    context['parser_brace'] -= 1
    mode = 'grammar' if context['parser_brace'] == 0 else mode
    return default_action(context, mode, match, groups, terminal, resource, line, col)
def parser_rule_start(context, mode, match, groups, terminal, resource, line, col):
    tokens = [
        Terminal(terminals['ll1_rule_hint'], 'll1_rule_hint', '', resource, line, col),
        Terminal(terminals[terminal], terminal, normalize_morpheme(match), resource, line, col)
    ]
    return (tokens, mode, context)
def infix_rule_start(context, mode, match, groups, terminal, resource, line, col):
    nonterminal = normalize_morpheme(re.search('\$[a-zA-Z][a-zA-Z0-9_]*', match).group(0))
    operator = normalize_morpheme(re.search(':[a-zA-Z][a-zA-Z0-9_]*', match).group(0))
    tokens = [
        Terminal(terminals['expr_rule_hint'], 'expr_rule_hint', '', resource, line, col),
        Terminal(terminals['nonterminal'], 'nonterminal', nonterminal, resource, line, col),
        Terminal(terminals['equals'], 'equals', '=', resource, line, col),
        Terminal(terminals['infix_rule_hint'], 'infix_rule_hint', '', resource, line, col),
        Terminal(terminals['nonterminal'], 'nonterminal', nonterminal, resource, line, col),
        Terminal(terminals['terminal'], 'terminal', operator, resource, line, col),
        Terminal(terminals['nonterminal'], 'nonterminal', nonterminal, resource, line, col),
    ]
    return (tokens, mode, context)
def prefix_rule_start(context, mode, match, groups, terminal, resource, line, col):
    nonterminal = normalize_morpheme(re.search('\$[a-zA-Z][a-zA-Z0-9_]*', match).group(0))
    operator = normalize_morpheme(re.search(':[a-zA-Z][a-zA-Z0-9_]*', match).group(0))
    tokens = [
        Terminal(terminals['expr_rule_hint'], 'expr_rule_hint', '', resource, line, col),
        Terminal(terminals['nonterminal'], 'nonterminal', nonterminal, resource, line, col),
        Terminal(terminals['equals'], 'equals', '=', resource, line, col),
        Terminal(terminals['prefix_rule_hint'], 'prefix_rule_hint', '', resource, line, col),
        Terminal(terminals['terminal'], 'terminal', operator, resource, line, col),
        Terminal(terminals['nonterminal'], 'nonterminal', nonterminal, resource, line, col),
    ]
    return (tokens, mode, context)
def expr_rule_start(context, mode, match, groups, terminal, resource, line, col):
    nonterminal = normalize_morpheme(re.search('\$[a-zA-Z][a-zA-Z0-9_]*', match).group(0))
    tokens = [
        Terminal(terminals['expr_rule_hint'], 'expr_rule_hint', '', resource, line, col),
        Terminal(terminals['nonterminal'], 'nonterminal', nonterminal, resource, line, col),
        Terminal(terminals['equals'], 'equals', '=', resource, line, col),
        Terminal(terminals['mixfix_rule_hint'], 'mixfix_rule_hint', '',resource, line, col),
    ]
    return (tokens, mode, context)
def grammar_lbrace(context, mode, match, groups, terminal, resource, line, col):
    context['grammar_brace'] += 1
    return default_action(context, mode, match, groups, terminal, resource, line, col)
def grammar_rbrace(context, mode, match, groups, terminal, resource, line, col):
    context['grammar_brace'] -= 1
    mode = 'default' if context['parser_brace'] == 0 else mode
    return default_action(context, mode, match, groups, terminal, resource, line, col)
    </code>
  }

  parser<ll1> {
    $grammar = :grammar :lbrace list($body_element) :rbrace -> Grammar(body=$2)
    $body_element = $body_element_sub -> $0
    $body_element_sub = $lexer | $parser
    $lexer = :lexer :langle :identifier :rangle :lbrace list($lexer_atom) optional(:code) :rbrace -> Lexer(language=$2, atoms=$5, code=$6)
    $lexer_atom = $lexer_regex | $lexer_mode | $lexer_partials
    $lexer_partials = :partials :lbrace list($regex_partial) :rbrace -> RegexPartials(list=$2)
    $regex_partial = :regex :arrow :regex_partial -> RegexPartial(regex=$0, name=$2)
    $lexer_regex = :regex optional($regex_options) :arrow $lexer_target -> Regex(regex=$0, options=$1, onmatch=$3)
    $regex_options = :lbrace list(:identifier) :rbrace -> $1
    $lexer_target = :terminal
    $lexer_target = :identifier :lparen optional(:terminal) :rparen -> LexerFunctionCall(name=$0, terminal=$2)
    $lexer_target = :null -> Null()
    $lexer_mode = :mode :langle :identifier :rangle :lbrace list($lexer_atom) :rbrace -> Mode(name=$2, atoms=$5)
    $parser = $parser_ll1 | $parser_expression
    $parser_ll1 = :parser_ll1 :lbrace list($ll1_rule) :rbrace -> Parser(rules=$2)
    $ll1_rule = :ll1_rule_hint :nonterminal :equals $ll1_rule_rhs -> Rule(nonterminal=$1, production=$3)
    $ll1_rule_rhs = list($rule, :pipe)
    $rule = list($morpheme) optional($ast_transform) -> Production(morphemes=$0, ast=$1)
    $ll1_rule_rhs = :null -> NullProduction()
    $ll1_rule_rhs = $parser
    $parser_expression = :parser_expression :lbrace list($expression_rule) :rbrace -> ExpressionParser(rules=$2)
    $expression_rule = optional($binding_power) :expr_rule_hint :nonterminal :equals $expression_rule_production -> ExpressionRule(precedence=$0, nonterminal=$2, production=$4)
    $expression_rule_production = :mixfix_rule_hint $nud optional($ast_transform) optional($led) optional($ast_transform) -> MixfixProduction(nud=$1, nud_ast=$2, led=$3, ast=$4)
    $expression_rule_production = :prefix_rule_hint list($morpheme) optional($ast_transform) -> PrefixProduction(morphemes=$1, ast=$2)
    $expression_rule_production = :infix_rule_hint list($morpheme) optional($ast_transform) -> InfixProduction(morphemes=$1, ast=$2)
    $nud = list($morpheme)
    $led = :expression_divider list($morpheme) -> $1
    $binding_power = :lparen $precedence :rparen -> $1
    $precedence = $binding_power_marker :colon $associativity -> Precedence(marker=$0, associativity=$2)
    $binding_power_marker = :asterisk | :dash
    $associativity = :left | :right | :unary
    $morpheme = :terminal | :nonterminal | $macro
    $ast_transform = :arrow $ast_transform_sub -> $1
    $ast_transform_sub = :identifier :lparen list($ast_parameter, :comma) :rparen -> AstTransformation(name=$0, parameters=$2)
    $ast_transform_sub = :nonterminal_reference
    $ast_parameter = :identifier :equals :nonterminal_reference -> AstParameter(name=$0, index=$2)
    $macro = :identifier :lparen list($macro_parameter, :comma) :rparen -> Macro(name=$0, parameters=$2)
    $macro_parameter = :nonterminal | :terminal | :string | :integer
  }
}
